services:
  spark-executor-nginx:
    container_name: spark-executor-nginx
    hostname: spark-executor-nginx
    image: nginx:stable-perl
    volumes:
      - ./conf/nginx.conf:/etc/nginx/nginx.conf
      - ../certs/${DOMAIN_NAME}.crt:/opt/certs/${DOMAIN_NAME}.crt:ro
      - ../certs/${DOMAIN_NAME}.key:/opt/certs/${DOMAIN_NAME}.key:ro
    ports:
      - ${SPARK_JUPYTER_NOTEBOOK_PORT}:443
    networks:
      spark-iceberg-client-network:
        ipv4_address: 172.20.0.35
    restart: always
  spark-executor:
    container_name: spark-executor
    hostname: spark-executor
    build: .
    ports:
      - ${SPARK_APPLICATION_WEB_UI_PORT}:8080
      - ${SPARK_JOB_HISTORY_WEB_UI_PORT}:4040
    tty: true
#    user: root
    volumes:
      - ./conf/spark-defaults.conf:/opt/spark-3.5.5-bin-hadoop3-scala2.13/conf/spark-defaults.conf:ro
      - ./data/:/home/spark/data/:rw
      - ./py/:/home/spark/py/:rw
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
      - AWS_S3_ENDPOINT=${DOMAIN_NAME}:9000
      - AWS_REGION=us-east-1
      - TZ=Asia/Tokyo
    networks:
      spark-iceberg-client-network:
        ipv4_address: 172.20.0.34
    restart: always
networks:
  spark-iceberg-client-network:
    driver: bridge
    ipam:
      driver: default
      config:
      - subnet: 172.20.0.32/29
        gateway: 172.20.0.33
